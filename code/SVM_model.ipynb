{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (16,122) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"source-data/PERM_2017.csv\")\n",
    "df = df.append(pd.read_csv(\"source-data/PERM_2018.csv\"),sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using 0.03 of orginal data for our model.\n",
      "Original data: pass -> 5897 Denied -> 391\n",
      "Expanded data: pass -> 5897 Denied -> 4301\n",
      "Using 0.3 of data as training data.\n",
      "Buidling SVM Classifier model ......\n",
      "Accuracy using test data:  0.8982764447448462\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Transform YES/No --> 1/0.\n",
    "def to_binary_numeric(series):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    series = series.astype(str).apply(le.fit_transform)\n",
    "    df = pd.DataFrame.from_records(series)\n",
    "    return df\n",
    "\n",
    "# Transform categorical data column to one hot encoding columns.\n",
    "def to_one_hot_encoding(series):\n",
    "    series = to_binary_numeric(series)\n",
    "    enc = preprocessing.OneHotEncoder()\n",
    "    enc.fit(series)\n",
    "    series = enc.transform(series).toarray()\n",
    "    df = pd.DataFrame.from_records(series)\n",
    "    return df\n",
    "\n",
    "# Normalize a column.\n",
    "def normalize(column):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    column_reshaped = column.values.reshape(-1, 1)\n",
    "    column_scaled = min_max_scaler.fit_transform(column_reshaped)\n",
    "    return pd.DataFrame(column_scaled)\n",
    "\n",
    "\n",
    "# Make a copy of the data we just imported.\n",
    "data = df.copy()\n",
    "\n",
    "\n",
    "''' ----- pre-process lable y (CASE_STATUS) ----- '''\n",
    "\n",
    "# In order to train a model we need to reduce the amount of data we use.\n",
    "percentile = 0.03\n",
    "print(\"We are using\", percentile, \"of orginal data for our model.\")\n",
    "data = data.sample(frac=percentile, random_state=250)\n",
    "data = data.fillna(0)\n",
    "\n",
    "# CASE_STATUS is our predicting lable. We need to transfrom its string format into numerical data.\n",
    "data[\"CASE_STATUS\"] = data[\"CASE_STATUS\"].map({'Certified':1,'Certified-Expired':1,'Withdrawn':0, 'Denied':-1})\n",
    "\n",
    "# Number of people get accepted is much bigger than number of people get rejected.\n",
    "# In order to make our model unbiased we need to increase number of people get rejected.\n",
    "rows_passed = data.loc[data[\"CASE_STATUS\"] == 1]\n",
    "rows_denied = data.loc[data[\"CASE_STATUS\"] == -1]\n",
    "print(\"Original data: pass ->\",len(rows_passed),\"Denied ->\",len(rows_denied))\n",
    "for i in range(0,10):\n",
    "    data = data.append(rows_denied,ignore_index=True)\n",
    "rows_passed = data.loc[data[\"CASE_STATUS\"] == 1]\n",
    "rows_denied = data.loc[data[\"CASE_STATUS\"] == -1]\n",
    "print(\"Expanded data: pass ->\",len(rows_passed),\"Denied ->\",len(rows_denied))\n",
    "\n",
    "\n",
    "\n",
    "''' ----- pre-process Attributes X ----- '''\n",
    "\n",
    "# Process REFILE\n",
    "data['REFILE'] = to_binary_numeric(data[['REFILE']])\n",
    "data_for_classifier = pd.concat((data['REFILE'], pd.DataFrame(data[\"CASE_STATUS\"])), axis=1)\n",
    "\n",
    "# Process EMPLOYER_STATE\n",
    "EMPLOYER_STATE_columns = to_one_hot_encoding(data[['EMPLOYER_STATE']])\n",
    "data_for_classifier = pd.concat((EMPLOYER_STATE_columns, data_for_classifier), axis=1)\n",
    "\n",
    "# Process EMPLOYER_NUM_EMPLOYEES\n",
    "data['EMPLOYER_NUM_EMPLOYEES'] = normalize(data['EMPLOYER_NUM_EMPLOYEES'])\n",
    "data_for_classifier = pd.concat((data['EMPLOYER_NUM_EMPLOYEES'], data_for_classifier), axis=1)\n",
    "\n",
    "# Process FW_OWNERSHIP_INTEREST\n",
    "data['FW_OWNERSHIP_INTEREST'] = to_binary_numeric(data[['FW_OWNERSHIP_INTEREST']])\n",
    "data_for_classifier = pd.concat((data['FW_OWNERSHIP_INTEREST'], data_for_classifier), axis=1)\n",
    "\n",
    "# Process PW_SOC_CODE\n",
    "data['PW_SOC_CODE'] = [elem[:2] for elem in list(map(str, list(data['PW_SOC_CODE'])))]\n",
    "PW_SOC_CODE_columns = to_one_hot_encoding(data[['PW_SOC_CODE']])\n",
    "data_for_classifier = pd.concat((PW_SOC_CODE_columns, data_for_classifier), axis=1)\n",
    "\n",
    "# Process PW_LEVEL_9089\n",
    "data[\"PW_LEVEL_9089\"] = data[\"PW_LEVEL_9089\"].map({'Level I':1,'Level II':2,'Level IV':3, 'Level III':4})\n",
    "data_for_classifier = pd.concat((data[\"PW_LEVEL_9089\"], data_for_classifier), axis=1)\n",
    "\n",
    "# Process JOB_INFO_WORK_STATE\n",
    "JOB_INFO_WORK_STATE_columns = to_one_hot_encoding(data[['JOB_INFO_WORK_STATE']])\n",
    "data_for_classifier = pd.concat((JOB_INFO_WORK_STATE_columns, data_for_classifier), axis=1)\n",
    "\n",
    "# Process JOB_INFO_EDUCATION\n",
    "data[\"JOB_INFO_EDUCATION\"] = data[\"JOB_INFO_EDUCATION\"].map({\"None\":1,'Other':1,'High School':2, \"Associate's\":3, \"Bachelor's\":4, \"Master's\":5, 'Doctorate':6})\n",
    "data_for_classifier = pd.concat((data['JOB_INFO_EDUCATION'], data_for_classifier), axis=1)\n",
    "\n",
    "# Process JI_OFFERED_TO_SEC_J_FW\n",
    "data['JI_OFFERED_TO_SEC_J_FW'] = to_binary_numeric(data[['JI_OFFERED_TO_SEC_J_FW']])\n",
    "data_for_classifier = pd.concat((data['JI_OFFERED_TO_SEC_J_FW'], data_for_classifier), axis=1)\n",
    "\n",
    "# Process NAICS_US_CODE\n",
    "data['NAICS_US_CODE'] = [elem[:2] for elem in list(map(str, list(data['NAICS_US_CODE'])))]\n",
    "NAICS_US_CODE_columns = to_one_hot_encoding(data[['NAICS_US_CODE']])\n",
    "data_for_classifier = pd.concat((NAICS_US_CODE_columns, data_for_classifier), axis=1)\n",
    "\n",
    "# Process COUNTRY_OF_CITIZENSHIP\n",
    "COUNTRY_OF_CITIZENSHIP_columns = to_one_hot_encoding(data[['COUNTRY_OF_CITIZENSHIP']])\n",
    "data_for_classifier = pd.concat((COUNTRY_OF_CITIZENSHIP_columns, data_for_classifier), axis=1)\n",
    "\n",
    "# Process CLASS_OF_ADMISSION\n",
    "CLASS_OF_ADMISSION_columns = to_one_hot_encoding(data[['CLASS_OF_ADMISSION']])\n",
    "data_for_classifier = pd.concat((CLASS_OF_ADMISSION_columns, data_for_classifier), axis=1)\n",
    "\n",
    "# Process FOREIGN_WORKER_INFO_EDUCATION\n",
    "data[\"FOREIGN_WORKER_INFO_EDUCATION\"] = data[\"FOREIGN_WORKER_INFO_EDUCATION\"].map({\"0\":1,\"None\":1,'Other':1,'High School':2, \"Associate's\":3, \"Bachelor's\":4, \"Master's\":5, 'Doctorate':6})\n",
    "FOREIGN_WORKER_INFO_EDUCATION_columns = to_one_hot_encoding(data[['FOREIGN_WORKER_INFO_EDUCATION']])\n",
    "data_for_classifier = pd.concat((FOREIGN_WORKER_INFO_EDUCATION_columns, data_for_classifier), axis=1)\n",
    "\n",
    "# Process FW_INFO_TRAINING_COMP\n",
    "FW_INFO_TRAINING_COMP_columns = to_one_hot_encoding(data[['FW_INFO_TRAINING_COMP']])\n",
    "data_for_classifier = pd.concat((FW_INFO_TRAINING_COMP_columns, data_for_classifier), axis=1)\n",
    "\n",
    "# Process NAICS_US_CODE\n",
    "NAICS_US_CODE_columns = to_one_hot_encoding(data[['NAICS_US_CODE']])\n",
    "data_for_classifier = pd.concat((NAICS_US_CODE_columns, data_for_classifier), axis=1)\n",
    "\n",
    "# Process WAGE_OFFER_FROM_9089 and WAGE_OFFER_UNIT_OF_PAY_9089\n",
    "data[\"WAGE_OFFER_UNIT_OF_PAY_9089\"] = data[\"WAGE_OFFER_UNIT_OF_PAY_9089\"].map({\"Hour\":2085,\"Week\":52,'Month':12,'Year':1})\n",
    "data[\"WAGE_OFFER_FROM_9089\"] = pd.to_numeric(data[\"WAGE_OFFER_FROM_9089\"].astype(str).str.replace(',',''), errors='coerce').fillna(0).astype(int)\n",
    "salary = data.WAGE_OFFER_UNIT_OF_PAY_9089 * data.WAGE_OFFER_FROM_9089\n",
    "data_for_classifier = pd.concat((salary, data_for_classifier), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "''' ----- Build model with Support Vector Machine algorithm ----- '''\n",
    "\n",
    "# Dropna\n",
    "data_for_classifier = data_for_classifier.dropna()\n",
    "\n",
    "# 分成train和test\n",
    "y = data_for_classifier[\"CASE_STATUS\"]\n",
    "X = data_for_classifier.drop(columns=['CASE_STATUS'])\n",
    "\n",
    "train_per = 0.3\n",
    "print(\"Using\", train_per,\"of data as training data.\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(\"Buidling SVM Classifier model ......\")\n",
    "\n",
    "# train\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "acc = accuracy_score(y_test, clf.predict(X_test))\n",
    "print(\"Accuracy using test data: \",acc)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
